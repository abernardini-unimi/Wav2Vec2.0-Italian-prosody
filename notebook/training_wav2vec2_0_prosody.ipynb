{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/abernardini-unimi/Wav2Vec2.0-Italian-prosody.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIPo-H9g_q4_",
        "outputId": "8e7ce491-cd46-4106-a73b-588ea2ea7533"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Wav2Vec2.0-Italian-prosody'...\n",
            "remote: Enumerating objects: 3582, done.\u001b[K\n",
            "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 3582 (delta 5), reused 12 (delta 4), pack-reused 3567 (from 1)\u001b[K\n",
            "Receiving objects: 100% (3582/3582), 553.40 MiB | 16.01 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Updating files: 100% (3513/3513), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Wav2Vec2.0-Italian-prosody"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrTi8oVFAlB2",
        "outputId": "456fbf5b-982a-4cbc-8e25-73f1e70a30d5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Wav2Vec2.0-Italian-prosody\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python run_wav2vec_clf.py \\\n",
        "    --model_name_or_path facebook/wav2vec2-large-xlsr-53 \\\n",
        "    --train_file csv/train.csv \\\n",
        "    --validation_file csv/test.csv \\\n",
        "    --input_column path \\\n",
        "    --output_dir '/content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint' \\\n",
        "    --num_train_epochs 30 \\\n",
        "    --per_device_train_batch_size 32 \\\n",
        "    --gradient_accumulation_steps 4 \\\n",
        "    --per_device_eval_batch_size 16 \\\n",
        "    --learning_rate 1e-4 \\\n",
        "    --freeze_feature_extractor \\\n",
        "    --eval_strategy steps \\\n",
        "    --eval_steps 100 \\\n",
        "    --save_strategy steps \\\n",
        "    --save_steps 100 \\\n",
        "    --load_best_model_at_end \\\n",
        "    --bf16 \\\n",
        "    --do_train \\\n",
        "    --do_eval \\\n",
        "    --delimiter comma"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAnvdkcll3Oj",
        "outputId": "bbd604a6-bc15-4110-c4d1-4725bb0d83ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Could not set audio backend to soundfile: module 'torchaudio' has no attribute 'set_audio_backend'\n",
            "02/19/2026 15:43:05 - WARNING - __main__ -   Process rank: -1, device: cuda:0, n_gpu: 1distributed training: False, 16-bits training: False\n",
            "02/19/2026 15:43:05 - INFO - __main__ -   Training/evaluation parameters TrainingArguments(\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=True,\n",
            "batch_eval_metrics=False,\n",
            "bf16=True,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "do_eval=True,\n",
            "do_predict=False,\n",
            "do_train=True,\n",
            "enable_jit_checkpoint=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=100,\n",
            "eval_strategy=IntervalStrategy.STEPS,\n",
            "eval_use_gather_object=False,\n",
            "fp16=False,\n",
            "fp16_full_eval=False,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=4,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=False,\n",
            "group_by_length=False,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_revision=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_num_input_tokens_seen=no,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=0.0001,\n",
            "length_column_name=length,\n",
            "liger_kernel_config=None,\n",
            "load_best_model_at_end=True,\n",
            "local_rank=-1,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=None,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs=None,\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=loss,\n",
            "neftune_noise_alpha=None,\n",
            "num_train_epochs=30.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=/content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint,\n",
            "parallelism_config=None,\n",
            "per_device_eval_batch_size=16,\n",
            "per_device_train_batch_size=32,\n",
            "prediction_loss_only=False,\n",
            "project=huggingface,\n",
            "push_to_hub=False,\n",
            "remove_unused_columns=True,\n",
            "report_to=[],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=None,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_steps=100,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "trackio_space_id=trackio,\n",
            "use_cache=False,\n",
            "use_cpu=False,\n",
            "use_liger_kernel=False,\n",
            "warmup_ratio=None,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "02/19/2026 15:43:05 - INFO - __main__ -   load a local file for train: csv/train.csv\n",
            "02/19/2026 15:43:05 - INFO - __main__ -   load a local file for validation: csv/test.csv\n",
            "02/19/2026 15:43:06 - INFO - __main__ -   *** Arousal-Valence-Dominance Regression (3 outputs) ***\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--wav2vec2-large-xlsr-53/snapshots/c3f9d884181a224a6ac87bf8885c84d1cff3384f/config.json\n",
            "Model config Wav2Vec2Config {\n",
            "  \"activation_dropout\": 0.0,\n",
            "  \"adapter_attn_dim\": null,\n",
            "  \"adapter_kernel_size\": 3,\n",
            "  \"adapter_stride\": 2,\n",
            "  \"add_adapter\": false,\n",
            "  \"apply_spec_augment\": true,\n",
            "  \"architectures\": [\n",
            "    \"Wav2Vec2ForPreTraining\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"bos_token_id\": 1,\n",
            "  \"classifier_proj_size\": 256,\n",
            "  \"codevector_dim\": 768,\n",
            "  \"contrastive_logits_temperature\": 0.1,\n",
            "  \"conv_bias\": true,\n",
            "  \"conv_dim\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512\n",
            "  ],\n",
            "  \"conv_kernel\": [\n",
            "    10,\n",
            "    3,\n",
            "    3,\n",
            "    3,\n",
            "    3,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"conv_stride\": [\n",
            "    5,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2,\n",
            "    2\n",
            "  ],\n",
            "  \"ctc_loss_reduction\": \"sum\",\n",
            "  \"ctc_zero_infinity\": false,\n",
            "  \"diversity_loss_weight\": 0.1,\n",
            "  \"do_stable_layer_norm\": true,\n",
            "  \"eos_token_id\": 2,\n",
            "  \"feat_extract_activation\": \"gelu\",\n",
            "  \"feat_extract_dropout\": 0.0,\n",
            "  \"feat_extract_norm\": \"layer\",\n",
            "  \"feat_proj_dropout\": 0.1,\n",
            "  \"feat_quantizer_dropout\": 0.0,\n",
            "  \"final_dropout\": 0.0,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout\": 0.1,\n",
            "  \"hidden_size\": 1024,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"arousal\",\n",
            "    \"1\": \"valence\",\n",
            "    \"2\": \"dominance\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 4096,\n",
            "  \"label2id\": {\n",
            "    \"arousal\": 0,\n",
            "    \"dominance\": 2,\n",
            "    \"valence\": 1\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-05,\n",
            "  \"layerdrop\": 0.1,\n",
            "  \"mask_channel_length\": 10,\n",
            "  \"mask_channel_min_space\": 1,\n",
            "  \"mask_channel_other\": 0.0,\n",
            "  \"mask_channel_prob\": 0.0,\n",
            "  \"mask_channel_selection\": \"static\",\n",
            "  \"mask_feature_length\": 10,\n",
            "  \"mask_feature_min_masks\": 0,\n",
            "  \"mask_feature_prob\": 0.0,\n",
            "  \"mask_time_length\": 10,\n",
            "  \"mask_time_min_masks\": 2,\n",
            "  \"mask_time_min_space\": 1,\n",
            "  \"mask_time_other\": 0.0,\n",
            "  \"mask_time_prob\": 0.075,\n",
            "  \"mask_time_selection\": \"static\",\n",
            "  \"model_type\": \"wav2vec2\",\n",
            "  \"num_adapter_layers\": 3,\n",
            "  \"num_attention_heads\": 16,\n",
            "  \"num_codevector_groups\": 2,\n",
            "  \"num_codevectors_per_group\": 320,\n",
            "  \"num_conv_pos_embedding_groups\": 16,\n",
            "  \"num_conv_pos_embeddings\": 128,\n",
            "  \"num_feat_extract_layers\": 7,\n",
            "  \"num_hidden_layers\": 24,\n",
            "  \"num_negatives\": 100,\n",
            "  \"output_hidden_size\": 1024,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"proj_codevector_dim\": 768,\n",
            "  \"tdnn_dilation\": [\n",
            "    1,\n",
            "    2,\n",
            "    3,\n",
            "    1,\n",
            "    1\n",
            "  ],\n",
            "  \"tdnn_dim\": [\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    512,\n",
            "    1500\n",
            "  ],\n",
            "  \"tdnn_kernel\": [\n",
            "    5,\n",
            "    3,\n",
            "    3,\n",
            "    1,\n",
            "    1\n",
            "  ],\n",
            "  \"transformers_version\": \"5.0.0\",\n",
            "  \"use_weighted_layer_sum\": false,\n",
            "  \"vocab_size\": 32,\n",
            "  \"xvector_output_dim\": 512\n",
            "}\n",
            "\n",
            "loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--facebook--wav2vec2-large-xlsr-53/snapshots/c3f9d884181a224a6ac87bf8885c84d1cff3384f/preprocessor_config.json\n",
            "Feature extractor Wav2Vec2FeatureExtractor {\n",
            "  \"do_normalize\": true,\n",
            "  \"feature_extractor_type\": \"Wav2Vec2FeatureExtractor\",\n",
            "  \"feature_size\": 1,\n",
            "  \"padding_side\": \"right\",\n",
            "  \"padding_value\": 0,\n",
            "  \"return_attention_mask\": true,\n",
            "  \"sampling_rate\": 16000\n",
            "}\n",
            "\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "02/19/2026 15:43:07 - WARNING - huggingface_hub.utils._http -   Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--wav2vec2-large-xlsr-53/snapshots/c3f9d884181a224a6ac87bf8885c84d1cff3384f/pytorch_model.bin\n",
            "Attempting to create safetensors variant\n",
            "Since the `dtype` attribute can't be found in model's config object, will use dtype={dtype} as derived from model's weights\n",
            "Loading weights:  34% 142/422 [00:00<00:00, 1048.80it/s, Materializing param=wav2vec2.encoder.layers.8.feed_forward.output_dense.weight]Safetensors PR exists\n",
            "Loading weights: 100% 422/422 [00:00<00:00, 702.34it/s, Materializing param=wav2vec2.masked_spec_embed]\n",
            "\u001b[1mWav2Vec2ForSpeechClassification LOAD REPORT\u001b[0m from: facebook/wav2vec2-large-xlsr-53\n",
            "Key                          | Status     | \n",
            "-----------------------------+------------+-\n",
            "project_q.bias               | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "quantizer.codevectors        | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "quantizer.weight_proj.bias   | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "quantizer.weight_proj.weight | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "project_q.weight             | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "project_hid.bias             | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "project_hid.weight           | \u001b[38;5;208mUNEXPECTED\u001b[0m | \n",
            "classifier.out_proj.weight   | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.dense.weight      | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.out_proj.bias     | \u001b[31mMISSING\u001b[0m    | \n",
            "classifier.dense.bias        | \u001b[31mMISSING\u001b[0m    | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "- \u001b[31mMISSING\u001b[0m\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n",
            "02/19/2026 15:43:08 - INFO - __main__ -   Split sizes: 2800 train\n",
            "02/19/2026 15:43:08 - INFO - __main__ -   Split sizes: 700 validation\n",
            "02/19/2026 15:43:09 - INFO - __main__ -   *** Training from: /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-880 ***\n",
            "Loading model from /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-880.\n",
            "The following columns in the Training set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "***** Running training *****\n",
            "  Num examples = 2,800\n",
            "  Num Epochs = 30\n",
            "  Instantaneous batch size per device = 32\n",
            "  Training with DataParallel so batch size has been adjusted to: 16\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 4\n",
            "  Total optimization steps = 1,320\n",
            "  Number of trainable parameters = 312,281,219\n",
            "Warning: The following arguments do not match the ones in the `trainer_state.json` within the checkpoint directory: \n",
            "\tper_device_train_batch_size: 32 (from args) != 16 (from trainer_state.json)\n",
            "  Continuing training from checkpoint, will skip to saved global_step\n",
            "  Continuing training from epoch 20\n",
            "  Continuing training from global step 880\n",
            "  Will skip the first 20 epochs then the first 0 batches in the first epoch.\n",
            " 68% 895/1320 [00:36<00:38, 10.90it/s]The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/44 [00:00<00:11,  3.53it/s]\u001b[A\n",
            "  7% 3/44 [00:01<00:16,  2.50it/s]\u001b[A\n",
            "  9% 4/44 [00:01<00:18,  2.14it/s]\u001b[A\n",
            " 11% 5/44 [00:02<00:19,  1.98it/s]\u001b[A\n",
            " 14% 6/44 [00:02<00:19,  1.98it/s]\u001b[A\n",
            " 16% 7/44 [00:03<00:18,  1.95it/s]\u001b[A\n",
            " 18% 8/44 [00:03<00:18,  1.99it/s]\u001b[A\n",
            " 68% 900/1320 [00:53<00:38, 10.90it/s]\n",
            " 23% 10/44 [00:04<00:17,  1.95it/s]\u001b[A\n",
            " 25% 11/44 [00:05<00:16,  1.99it/s]\u001b[A\n",
            " 27% 12/44 [00:05<00:16,  1.98it/s]\u001b[A\n",
            " 30% 13/44 [00:06<00:15,  1.98it/s]\u001b[A\n",
            " 32% 14/44 [00:06<00:15,  1.91it/s]\u001b[A\n",
            " 34% 15/44 [00:07<00:15,  1.85it/s]\u001b[A\n",
            " 36% 16/44 [00:08<00:15,  1.77it/s]\u001b[A\n",
            " 39% 17/44 [00:08<00:14,  1.80it/s]\u001b[A\n",
            " 41% 18/44 [00:09<00:14,  1.84it/s]\u001b[A\n",
            " 43% 19/44 [00:09<00:13,  1.92it/s]\u001b[A\n",
            " 45% 20/44 [00:10<00:12,  1.92it/s]\u001b[A\n",
            " 48% 21/44 [00:10<00:12,  1.90it/s]\u001b[A\n",
            " 50% 22/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 52% 23/44 [00:11<00:11,  1.89it/s]\u001b[A\n",
            " 55% 24/44 [00:12<00:10,  1.93it/s]\u001b[A\n",
            " 57% 25/44 [00:12<00:09,  1.91it/s]\u001b[A\n",
            " 59% 26/44 [00:13<00:09,  1.93it/s]\u001b[A\n",
            " 61% 27/44 [00:13<00:08,  2.01it/s]\u001b[A\n",
            " 64% 28/44 [00:14<00:08,  1.98it/s]\u001b[A\n",
            " 66% 29/44 [00:14<00:07,  1.94it/s]\u001b[A\n",
            " 68% 30/44 [00:15<00:07,  1.92it/s]\u001b[A\n",
            " 70% 31/44 [00:15<00:06,  1.93it/s]\u001b[A\n",
            " 73% 32/44 [00:16<00:06,  1.94it/s]\u001b[A\n",
            " 75% 33/44 [00:16<00:05,  1.94it/s]\u001b[A\n",
            " 77% 34/44 [00:17<00:05,  1.92it/s]\u001b[A\n",
            " 80% 35/44 [00:17<00:04,  1.97it/s]\u001b[A\n",
            " 82% 36/44 [00:18<00:04,  1.98it/s]\u001b[A\n",
            " 84% 37/44 [00:18<00:03,  1.98it/s]\u001b[A\n",
            " 86% 38/44 [00:19<00:03,  1.95it/s]\u001b[A\n",
            " 89% 39/44 [00:19<00:02,  1.92it/s]\u001b[A\n",
            " 91% 40/44 [00:20<00:02,  1.93it/s]\u001b[A\n",
            " 93% 41/44 [00:20<00:01,  1.99it/s]\u001b[A\n",
            " 95% 42/44 [00:21<00:01,  1.98it/s]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': '0.4735', 'eval_ccc_arousal': '0.5851', 'eval_ccc_valence': '0.4346', 'eval_ccc_dominance': '0.6359', 'eval_ccc_mean': '0.5519', 'eval_mse': '0.03465', 'eval_runtime': '22.91', 'eval_samples_per_second': '30.55', 'eval_steps_per_second': '1.92', 'epoch': '20.46'}\n",
            " 68% 900/1320 [01:10<00:38, 10.90it/s]\n",
            "100% 44/44 [00:21<00:00,  2.11it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-900\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-900/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.10s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-900/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-900/preprocessor_config.json\n",
            "{'loss': '0.4679', 'grad_norm': '56.18', 'learning_rate': '2.432e-05', 'epoch': '22.73'}\n",
            " 76% 1000/1320 [05:21<12:51,  2.41s/it]The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/44 [00:00<00:12,  3.46it/s]\u001b[A\n",
            "  7% 3/44 [00:01<00:16,  2.46it/s]\u001b[A\n",
            "  9% 4/44 [00:01<00:18,  2.12it/s]\u001b[A\n",
            " 11% 5/44 [00:02<00:19,  1.97it/s]\u001b[A\n",
            " 14% 6/44 [00:02<00:19,  1.97it/s]\u001b[A\n",
            " 16% 7/44 [00:03<00:19,  1.94it/s]\u001b[A\n",
            " 18% 8/44 [00:03<00:18,  1.97it/s]\u001b[A\n",
            " 20% 9/44 [00:04<00:17,  1.99it/s]\u001b[A\n",
            " 23% 10/44 [00:04<00:17,  1.94it/s]\u001b[A\n",
            " 25% 11/44 [00:05<00:16,  1.98it/s]\u001b[A\n",
            " 27% 12/44 [00:05<00:16,  1.98it/s]\u001b[A\n",
            " 30% 13/44 [00:06<00:15,  1.99it/s]\u001b[A\n",
            " 32% 14/44 [00:06<00:15,  1.91it/s]\u001b[A\n",
            " 34% 15/44 [00:07<00:15,  1.87it/s]\u001b[A\n",
            " 36% 16/44 [00:08<00:15,  1.78it/s]\u001b[A\n",
            " 39% 17/44 [00:08<00:14,  1.81it/s]\u001b[A\n",
            " 41% 18/44 [00:09<00:14,  1.85it/s]\u001b[A\n",
            " 43% 19/44 [00:09<00:12,  1.93it/s]\u001b[A\n",
            " 45% 20/44 [00:10<00:12,  1.92it/s]\u001b[A\n",
            " 48% 21/44 [00:10<00:12,  1.91it/s]\u001b[A\n",
            " 50% 22/44 [00:11<00:11,  1.91it/s]\u001b[A\n",
            " 52% 23/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 55% 24/44 [00:12<00:10,  1.94it/s]\u001b[A\n",
            " 57% 25/44 [00:12<00:09,  1.92it/s]\u001b[A\n",
            " 59% 26/44 [00:13<00:09,  1.93it/s]\u001b[A\n",
            " 61% 27/44 [00:13<00:08,  2.01it/s]\u001b[A\n",
            " 64% 28/44 [00:14<00:08,  1.97it/s]\u001b[A\n",
            " 66% 29/44 [00:14<00:07,  1.94it/s]\u001b[A\n",
            " 68% 30/44 [00:15<00:07,  1.91it/s]\u001b[A\n",
            " 70% 31/44 [00:15<00:06,  1.91it/s]\u001b[A\n",
            " 73% 32/44 [00:16<00:06,  1.93it/s]\u001b[A\n",
            " 75% 33/44 [00:16<00:05,  1.92it/s]\u001b[A\n",
            " 77% 34/44 [00:17<00:05,  1.90it/s]\u001b[A\n",
            " 80% 35/44 [00:17<00:04,  1.96it/s]\u001b[A\n",
            " 82% 36/44 [00:18<00:04,  1.97it/s]\u001b[A\n",
            " 84% 37/44 [00:18<00:03,  1.98it/s]\u001b[A\n",
            " 86% 38/44 [00:19<00:03,  1.96it/s]\u001b[A\n",
            " 89% 39/44 [00:19<00:02,  1.92it/s]\u001b[A\n",
            " 91% 40/44 [00:20<00:02,  1.93it/s]\u001b[A\n",
            " 93% 41/44 [00:20<00:01,  1.99it/s]\u001b[A\n",
            " 95% 42/44 [00:21<00:01,  1.96it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': '0.4677', 'eval_ccc_arousal': '0.5862', 'eval_ccc_valence': '0.4657', 'eval_ccc_dominance': '0.627', 'eval_ccc_mean': '0.5596', 'eval_mse': '0.02862', 'eval_runtime': '22.94', 'eval_samples_per_second': '30.51', 'eval_steps_per_second': '1.918', 'epoch': '22.73'}\n",
            " 76% 1000/1320 [05:44<12:51,  2.41s/it]\n",
            "100% 44/44 [00:21<00:00,  2.09it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1000/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.43s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1000/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1000/preprocessor_config.json\n",
            " 83% 1100/1320 [09:53<07:19,  2.00s/it]The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/44 [00:00<00:11,  3.55it/s]\u001b[A\n",
            "  7% 3/44 [00:01<00:16,  2.50it/s]\u001b[A\n",
            "  9% 4/44 [00:01<00:18,  2.13it/s]\u001b[A\n",
            " 11% 5/44 [00:02<00:19,  1.99it/s]\u001b[A\n",
            " 14% 6/44 [00:02<00:19,  2.00it/s]\u001b[A\n",
            " 16% 7/44 [00:03<00:18,  1.97it/s]\u001b[A\n",
            " 18% 8/44 [00:03<00:17,  2.01it/s]\u001b[A\n",
            " 20% 9/44 [00:04<00:17,  2.01it/s]\u001b[A\n",
            " 23% 10/44 [00:04<00:17,  1.97it/s]\u001b[A\n",
            " 25% 11/44 [00:05<00:16,  2.00it/s]\u001b[A\n",
            " 27% 12/44 [00:05<00:16,  1.99it/s]\u001b[A\n",
            " 30% 13/44 [00:06<00:15,  1.99it/s]\u001b[A\n",
            " 32% 14/44 [00:06<00:15,  1.91it/s]\u001b[A\n",
            " 34% 15/44 [00:07<00:15,  1.86it/s]\u001b[A\n",
            " 36% 16/44 [00:08<00:15,  1.79it/s]\u001b[A\n",
            " 39% 17/44 [00:08<00:14,  1.81it/s]\u001b[A\n",
            " 41% 18/44 [00:09<00:14,  1.85it/s]\u001b[A\n",
            " 43% 19/44 [00:09<00:12,  1.93it/s]\u001b[A\n",
            " 45% 20/44 [00:10<00:12,  1.93it/s]\u001b[A\n",
            " 48% 21/44 [00:10<00:11,  1.92it/s]\u001b[A\n",
            " 50% 22/44 [00:11<00:11,  1.92it/s]\u001b[A\n",
            " 52% 23/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 55% 24/44 [00:12<00:10,  1.93it/s]\u001b[A\n",
            " 57% 25/44 [00:12<00:09,  1.92it/s]\u001b[A\n",
            " 59% 26/44 [00:13<00:09,  1.92it/s]\u001b[A\n",
            " 61% 27/44 [00:13<00:08,  2.01it/s]\u001b[A\n",
            " 64% 28/44 [00:14<00:08,  1.96it/s]\u001b[A\n",
            " 66% 29/44 [00:14<00:07,  1.93it/s]\u001b[A\n",
            " 68% 30/44 [00:15<00:07,  1.90it/s]\u001b[A\n",
            " 70% 31/44 [00:15<00:06,  1.91it/s]\u001b[A\n",
            " 73% 32/44 [00:16<00:06,  1.93it/s]\u001b[A\n",
            " 75% 33/44 [00:16<00:05,  1.93it/s]\u001b[A\n",
            " 77% 34/44 [00:17<00:05,  1.90it/s]\u001b[A\n",
            " 80% 35/44 [00:17<00:04,  1.96it/s]\u001b[A\n",
            " 82% 36/44 [00:18<00:04,  1.97it/s]\u001b[A\n",
            " 84% 37/44 [00:18<00:03,  1.97it/s]\u001b[A\n",
            " 86% 38/44 [00:19<00:03,  1.94it/s]\u001b[A\n",
            " 89% 39/44 [00:19<00:02,  1.90it/s]\u001b[A\n",
            " 91% 40/44 [00:20<00:02,  1.92it/s]\u001b[A\n",
            " 93% 41/44 [00:20<00:01,  1.97it/s]\u001b[A\n",
            " 95% 42/44 [00:21<00:01,  1.96it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': '0.4402', 'eval_ccc_arousal': '0.6229', 'eval_ccc_valence': '0.4795', 'eval_ccc_dominance': '0.6665', 'eval_ccc_mean': '0.5897', 'eval_mse': '0.02696', 'eval_runtime': '22.9', 'eval_samples_per_second': '30.57', 'eval_steps_per_second': '1.921', 'epoch': '25'}\n",
            " 83% 1100/1320 [10:16<07:19,  2.00s/it]\n",
            "100% 44/44 [00:21<00:00,  2.09it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1100\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1100/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.29s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1100/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1100/preprocessor_config.json\n",
            " 91% 1200/1320 [14:26<04:45,  2.38s/it]The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/44 [00:00<00:12,  3.45it/s]\u001b[A\n",
            "  7% 3/44 [00:01<00:16,  2.48it/s]\u001b[A\n",
            "  9% 4/44 [00:01<00:18,  2.13it/s]\u001b[A\n",
            " 11% 5/44 [00:02<00:19,  1.98it/s]\u001b[A\n",
            " 14% 6/44 [00:02<00:19,  1.97it/s]\u001b[A\n",
            " 16% 7/44 [00:03<00:19,  1.94it/s]\u001b[A\n",
            " 18% 8/44 [00:03<00:18,  1.99it/s]\u001b[A\n",
            " 20% 9/44 [00:04<00:17,  2.00it/s]\u001b[A\n",
            " 23% 10/44 [00:04<00:17,  1.95it/s]\u001b[A\n",
            " 25% 11/44 [00:05<00:16,  1.99it/s]\u001b[A\n",
            " 27% 12/44 [00:05<00:16,  1.98it/s]\u001b[A\n",
            " 30% 13/44 [00:06<00:15,  1.98it/s]\u001b[A\n",
            " 32% 14/44 [00:06<00:15,  1.90it/s]\u001b[A\n",
            " 34% 15/44 [00:07<00:15,  1.85it/s]\u001b[A\n",
            " 36% 16/44 [00:08<00:15,  1.76it/s]\u001b[A\n",
            " 39% 17/44 [00:08<00:15,  1.79it/s]\u001b[A\n",
            " 41% 18/44 [00:09<00:14,  1.83it/s]\u001b[A\n",
            " 43% 19/44 [00:09<00:13,  1.91it/s]\u001b[A\n",
            " 45% 20/44 [00:10<00:12,  1.91it/s]\u001b[A\n",
            " 48% 21/44 [00:10<00:12,  1.90it/s]\u001b[A\n",
            " 50% 22/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 52% 23/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 55% 24/44 [00:12<00:10,  1.93it/s]\u001b[A\n",
            " 57% 25/44 [00:12<00:09,  1.93it/s]\u001b[A\n",
            " 59% 26/44 [00:13<00:09,  1.94it/s]\u001b[A\n",
            " 61% 27/44 [00:13<00:08,  2.01it/s]\u001b[A\n",
            " 64% 28/44 [00:14<00:08,  1.98it/s]\u001b[A\n",
            " 66% 29/44 [00:14<00:07,  1.94it/s]\u001b[A\n",
            " 68% 30/44 [00:15<00:07,  1.92it/s]\u001b[A\n",
            " 70% 31/44 [00:15<00:06,  1.91it/s]\u001b[A\n",
            " 73% 32/44 [00:16<00:06,  1.93it/s]\u001b[A\n",
            " 75% 33/44 [00:16<00:05,  1.93it/s]\u001b[A\n",
            " 77% 34/44 [00:17<00:05,  1.90it/s]\u001b[A\n",
            " 80% 35/44 [00:17<00:04,  1.96it/s]\u001b[A\n",
            " 82% 36/44 [00:18<00:04,  1.96it/s]\u001b[A\n",
            " 84% 37/44 [00:18<00:03,  1.96it/s]\u001b[A\n",
            " 86% 38/44 [00:19<00:03,  1.94it/s]\u001b[A\n",
            " 89% 39/44 [00:20<00:02,  1.91it/s]\u001b[A\n",
            " 91% 40/44 [00:20<00:02,  1.93it/s]\u001b[A\n",
            " 93% 41/44 [00:20<00:01,  1.98it/s]\u001b[A\n",
            " 95% 42/44 [00:21<00:01,  1.96it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': '0.4376', 'eval_ccc_arousal': '0.6145', 'eval_ccc_valence': '0.5016', 'eval_ccc_dominance': '0.6626', 'eval_ccc_mean': '0.5929', 'eval_mse': '0.02605', 'eval_runtime': '22.98', 'eval_samples_per_second': '30.46', 'eval_steps_per_second': '1.915', 'epoch': '27.27'}\n",
            " 91% 1200/1320 [14:49<04:45,  2.38s/it]\n",
            "100% 44/44 [00:21<00:00,  2.09it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1200\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1200/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.08s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1200/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1200/preprocessor_config.json\n",
            " 98% 1300/1320 [19:01<00:47,  2.39s/it]The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "\n",
            "  0% 0/44 [00:00<?, ?it/s]\u001b[A\n",
            "  5% 2/44 [00:00<00:12,  3.47it/s]\u001b[A\n",
            "  7% 3/44 [00:01<00:16,  2.47it/s]\u001b[A\n",
            "  9% 4/44 [00:01<00:18,  2.14it/s]\u001b[A\n",
            " 11% 5/44 [00:02<00:19,  1.97it/s]\u001b[A\n",
            " 14% 6/44 [00:02<00:19,  1.96it/s]\u001b[A\n",
            " 16% 7/44 [00:03<00:19,  1.93it/s]\u001b[A\n",
            " 18% 8/44 [00:03<00:18,  1.97it/s]\u001b[A\n",
            " 20% 9/44 [00:04<00:17,  1.98it/s]\u001b[A\n",
            " 23% 10/44 [00:04<00:17,  1.94it/s]\u001b[A\n",
            " 25% 11/44 [00:05<00:16,  1.97it/s]\u001b[A\n",
            " 27% 12/44 [00:05<00:16,  1.98it/s]\u001b[A\n",
            " 30% 13/44 [00:06<00:15,  1.98it/s]\u001b[A\n",
            " 32% 14/44 [00:06<00:15,  1.90it/s]\u001b[A\n",
            " 34% 15/44 [00:07<00:15,  1.84it/s]\u001b[A\n",
            " 36% 16/44 [00:08<00:15,  1.76it/s]\u001b[A\n",
            " 39% 17/44 [00:08<00:15,  1.79it/s]\u001b[A\n",
            " 41% 18/44 [00:09<00:14,  1.83it/s]\u001b[A\n",
            " 43% 19/44 [00:09<00:13,  1.91it/s]\u001b[A\n",
            " 45% 20/44 [00:10<00:12,  1.91it/s]\u001b[A\n",
            " 48% 21/44 [00:10<00:12,  1.90it/s]\u001b[A\n",
            " 50% 22/44 [00:11<00:11,  1.90it/s]\u001b[A\n",
            " 52% 23/44 [00:11<00:11,  1.88it/s]\u001b[A\n",
            " 55% 24/44 [00:12<00:10,  1.92it/s]\u001b[A\n",
            " 57% 25/44 [00:12<00:09,  1.90it/s]\u001b[A\n",
            " 59% 26/44 [00:13<00:09,  1.91it/s]\u001b[A\n",
            " 61% 27/44 [00:13<00:08,  1.99it/s]\u001b[A\n",
            " 64% 28/44 [00:14<00:08,  1.94it/s]\u001b[A\n",
            " 66% 29/44 [00:14<00:07,  1.91it/s]\u001b[A\n",
            " 68% 30/44 [00:15<00:07,  1.90it/s]\u001b[A\n",
            " 70% 31/44 [00:15<00:06,  1.89it/s]\u001b[A\n",
            " 73% 32/44 [00:16<00:06,  1.91it/s]\u001b[A\n",
            " 75% 33/44 [00:16<00:05,  1.91it/s]\u001b[A\n",
            " 77% 34/44 [00:17<00:05,  1.88it/s]\u001b[A\n",
            " 80% 35/44 [00:18<00:04,  1.93it/s]\u001b[A\n",
            " 82% 36/44 [00:18<00:04,  1.94it/s]\u001b[A\n",
            " 84% 37/44 [00:19<00:03,  1.96it/s]\u001b[A\n",
            " 86% 38/44 [00:19<00:03,  1.92it/s]\u001b[A\n",
            " 89% 39/44 [00:20<00:02,  1.88it/s]\u001b[A\n",
            " 91% 40/44 [00:20<00:02,  1.90it/s]\u001b[A\n",
            " 93% 41/44 [00:21<00:01,  1.96it/s]\u001b[A\n",
            " 95% 42/44 [00:21<00:01,  1.94it/s]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': '0.4325', 'eval_ccc_arousal': '0.6147', 'eval_ccc_valence': '0.5216', 'eval_ccc_dominance': '0.6609', 'eval_ccc_mean': '0.5991', 'eval_mse': '0.02617', 'eval_runtime': '23.15', 'eval_samples_per_second': '30.24', 'eval_steps_per_second': '1.901', 'epoch': '29.55'}\n",
            " 98% 1300/1320 [19:24<00:47,  2.39s/it]\n",
            "100% 44/44 [00:22<00:00,  2.07it/s]\u001b[A\n",
            "                                   \u001b[ASaving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1300\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1300/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.14s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1300/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1300/preprocessor_config.json\n",
            "100% 1320/1320 [20:27<00:00,  2.10s/it]Saving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1320\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1320/config.json\n",
            "\n",
            "Writing model shards:   0% 0/1 [00:00<?, ?it/s]\u001b[A\n",
            "Writing model shards: 100% 1/1 [00:02<00:00,  2.16s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1320/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1320/preprocessor_config.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/checkpoint-1300 (score: 0.4325128495693207).\n",
            "{'train_runtime': '1245', 'train_samples_per_second': '67.48', 'train_steps_per_second': '1.06', 'train_loss': '0.1465', 'epoch': '30'}\n",
            "100% 1320/1320 [20:44<00:00,  1.06it/s]\n",
            "Saving model checkpoint to /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint\n",
            "Configuration saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/config.json\n",
            "Writing model shards: 100% 1/1 [00:26<00:00, 26.39s/it]\n",
            "Model weights saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/model.safetensors\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/preprocessor_config.json\n",
            "Feature extractor saved in /content/drive/MyDrive/Wav2vec2.0-prosody-Checkpoint/preprocessor_config.json\n",
            "***** train metrics *****\n",
            "  epoch                    =         30.0\n",
            "  total_flos               = 9005628843GF\n",
            "  train_loss               =       0.1465\n",
            "  train_runtime            =   0:20:44.71\n",
            "  train_samples            =         2800\n",
            "  train_samples_per_second =       67.485\n",
            "  train_steps_per_second   =         1.06\n",
            "02/19/2026 16:04:30 - INFO - __main__ -   *** Evaluate ***\n",
            "The following columns in the Evaluation set don't have a corresponding argument in `Wav2Vec2ForSpeechClassification.forward` and have been ignored: valence, dominance, path, arousal. If valence, dominance, path, arousal are not expected by `Wav2Vec2ForSpeechClassification.forward`,  you can safely ignore this message.\n",
            "\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 700\n",
            "  Batch size = 16\n",
            "100% 44/44 [00:22<00:00,  1.95it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       30.0\n",
            "  eval_ccc_arousal        =     0.6147\n",
            "  eval_ccc_dominance      =     0.6609\n",
            "  eval_ccc_mean           =     0.5991\n",
            "  eval_ccc_valence        =     0.5216\n",
            "  eval_loss               =     0.4325\n",
            "  eval_mse                =     0.0262\n",
            "  eval_runtime            = 0:00:23.54\n",
            "  eval_samples            =        700\n",
            "  eval_samples_per_second =     29.729\n",
            "  eval_steps_per_second   =      1.869\n"
          ]
        }
      ]
    }
  ]
}